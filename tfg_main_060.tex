%
% TÍTULO DEL CAPÍTULO
%
\chapter[ToView]{
	ToView
	\label{chapter_6}
}

ToView is how we named the visualizer that uses PCM under the hood, it was also implemented using C{}\verb!++!, OpenGL for visualization purposes and QT \cite{QT} for the user interface. All of these choices will be explained in the rest of the chapter.

\section[Design]{Design}

The visualizer has been implemented using \textbf{OpenGL 4.3} and \textbf{QT 5.3}. These two technologies were chosen so that the compatibility with multiple platforms was kept. Either OpenGL or QT are compatible with Windows, Linux and MacOS X.

On one hand, OpenGL is an API that allows an application to access and control the graphical system of the machine in which it is being executed. It could be a workstation with a high performance graphics card or a common desktop computer, a video-games console, etc.  

On the other hand, QT is a multi-platform graphical application creation framework. QT is open-source software that has been used and improved since it was created. It fits perfectly with our project since is C{}\verb!++! based. 

QT is used in more than 70 industries, by leading companies in their markets. QT is intuitive, has a suite for the design of interfaces called \textit{QT Designer} and plugins for the major development IDEs like Visual Studio.   

The compilers used as mentioned before are: Visual C{}\verb!++! in Windows systems, GCC in Linux and Clang in MacOS X.

\subsection[GUI]{Graphical User Interface}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{figures/GUI.pdf}
	\caption[User interface class diagram]{
		Class diagram of the user interface of ToView.
	}
	\label{GUI}
\end{figure}

In the \autoref{GUI}, one of the main classes is \textbf{MainWindow}. This class gives the user access to all the functionality of the visualizer, it will serve as the name implies, as the main window in the interface. This class will centralize all the functionality and access to secondary dialogs, as well as communicate with the OpenGL context and render thread. 

The OpenGL context is represented in the interface by the class \textbf{QGLFrame}, that is in charge of creating the corresponding OpenGL context, render thread and displaying each frame rendered. This class will also handle all the keyboard and mouse events.  

The \textbf{Segmentator} class, is a sub-dialog that will let the user input the parameters for the segmentation of primitives in the clouds. All of the choices are saved using the \textbf{Qsettings} class. This QT class simplifies the process of managing settings in an application, eliminating the need for custom configuration files. 

Furthermore, \textbf{Settings} is another sub-dialog that allows the user to configure several visualizer parameters. This dialog also relies on \textbf{QSettings} to store the settings permanently. 

Finally, \textbf{About} is just another sub-dialog that shows information about the software (version, authors, etc.). 

\subsection[Render thread]{Render thread}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{figures/render_thread.pdf}
	\caption[Render thread class diagram]{
		Class diagram of the render thread and its related classes.
	}
	\label{render_thread}
\end{figure}

As we can observe in \autoref{render_thread}, \textbf{QGLRenderThread} is a extremely complex class, that as its name hints, represents a render thread. This class will be in charge of initializing OpenGL, loading shaders, rendering, calculating the camera parameters, etc.

The thread is created by \textbf{QGLFrame}, next the OpenGL context will be transferred to that thread so that the rendering can begin. Rendering is done in a different thread than the GUI, so that the latter will still be responsive even in the most demanding cases. 

Because of this, the communication between the render thread and the GUI will make use of QT \textit{signals} and \textit{slots}\footnote{Language tool introduced in QT for communication between objects, which allows the implementation of the Observer pattern. The concept is that GUI widgets can send signals containing event information, which can be received by other objects using special functions known as slots.}. With these tools, the communication between the different threads will be robust and simpler. Since the render thread could also be used from multiple threads, we will also use a \textit{mutex} to secure concurrent accesses.

To access the cloud information in PCM, the external interface \textbf{PointCloud} is used. \textbf{PointCloud} will provide the necessary information to render the desired clouds; like node lists, point data, memory hierarchy management, etc.      

\subsection[Segmentation]{Segmentation}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{figures/segmentation.pdf}
	\caption[Segmentation class diagram]{
		Class diagram of the classes related to segmentation.
	}
	\label{segmentation_class}
\end{figure}

In \autoref{segmentation_class}, the classes related to the segmentation process are detailed. One of the most significant classes is \textbf{PointSampler}, this will be the class that samples the corresponding point cloud and then converts the data so that it is compatible with PCL. It also is capable of picking individual points for distance measurements, and storing them in a similar fashion to a STL vector for quick access.   

Next, the most important class will be briefly explained. \textbf{CloudSegmentator} uses the information obtained by \textbf{PointSampler} to segment three types of primitives, \textit{planes}, \textit{cylinders} and \textit{spheres}. But this is not all the functionality that this class provides, it is also capable of exporting these primitives to an AutoCAD compatible format. 

To achieve these objectives, this class uses the \textbf{RSampleConsensus} class for primitive fitting and \textbf{DL\_Dxf} for \textit{DXF}\footnote{\textit{Drawing Exchange Format} is a CAD data file format developed by Autodesk for enabling data interoperability between AutoCAD and other programs.} exporting. Since there is not a good way to export cylinders and spheres in the DXF format, the segmentator will also support exporting these primitives as \textit{SCR}\footnote{\textit{Script Files} are simply a list of AutoCAD commands.} files.

Since some of the primitives need normals for the segmentation process, \textbf{CloudSegmentator} also includes the capability to estimate them. The pattern \textit{Strategy} was used for the design of this class so that adding primitives in the future will be easy. 

\section[Functionality]{Functionality}

The need for a robust tool to complement PCM was quickly noticed when using PCM's basic visualizer. This tool was enough for testing but left a lot to be desired, even when multiple clouds were not rendered onscreen and no advanced operations were performed on them. 

Moreover, the rendering code was written with the help of an open source scene graph called OSG\footnote{Open Scene Graph}. This was also an inconvenient because of the massive nature of the clouds that this software is designed to deal with. Heavy optimization would have to be performed and complete access to OpenGL rendering code was needed.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.6]{figures/tovi_screen.png}
	\caption[Early ToView screenshot]{
		Screenshot showing an early version of ToView.
	}
	\label{early_toview}
\end{figure}

Furthermore, almost all of PCM's functionality was only accessible through multiple command line tools. When trying to integrate this software in engineering workflows, this was a big limitation.

If PCM was to be adopted by non-technical users, a GUI and more interactivity were essential. This is where ToView came to the rescue (see \autoref{early_toview}), with multiple cloud support, a GUI, advanced rendering, distance measuring capabilities, object detection, etc. All the functionality that ToView brings to the table will be exposed in the following subsections.

\subsection[Render modes]{Render modes}

In light of the need for high quality point based rendering, but also trying to keep versatility, three rendering modes are supported in ToView:

\begin{itemize}
	\item \textbf{Constant:} Most basic type of point-based rendering, it does not require point normals or radii.
	\item \textbf{Dynamic:} Almost the same as the previous mode, but requires point radii to reduce clipping and increase rendering quality and performance.
	\item \textbf{Perspective accurate:} Most advanced type of rendering, requires point normals and radii. This rendering mode yields high quality renders but at a greater computational cost.
\end{itemize}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.9]{figures/render_modes.png}
	\caption[Render modes]{
		Screenshot showing all of the available render modes in ToView's interface.
	}
	\label{render_modes}
\end{figure}

As we can see in \autoref{render_modes}, more parameters like anti-aliasing or full-screen rendering are also exposed through the GUI. Anti-aliasing will play a huge role in high quality rendering as it increases image quality dramatically.

All of these rendering modes and a complementary technique that was not exposed to the user in ToView, but was also implemented for testing, will be explained in depth in \autoref{chapter_7}.

\subsection[Camera types]{Camera types}

Since camera only one camera type was present in the old visualizer, two types of camera paradigms were implemented:

\begin{itemize}
	\item \textbf{First-person camera:} Type of camera that imitates how movement is implemented in video games. This camera is ideal for virtual tours of the scenes, or working with really big scenes with multiple objects.
	\item \textbf{Orbital:} This camera model emulates cameras in modeling software (Blender, AutoCAD, etc.). This camera type is optimal for working with single objects and an orthographic projection.
\end{itemize}

Furthermore, because of the engineering nature of our software, a perspective camera may not be the optimal choice. This is the reason why two types of projection are available for the user:

\begin{itemize}
	\item \textbf{Perspective:} Projection model that reflects how the human eye perceives scenes, objects in the distance appear smaller than objects close by. This projection type is useful when moving through a city or interior datasets. 
	\item \textbf{Ortographic:} This projection type ignores the aforementioned effect so that to-scale modeling can occur. This projection model is useful when working with single objects or when we need to see parallel lines as parallel in the final image.
\end{itemize}

All of these camera types are controlled using the keyboard and mouse, trying to make it as easy as possible for the end user. The math and implementation details behind these cameras are explained in \autoref{camera_model}. The options are exposed to the user through a convenient menu in the interface and do not require restarting the application to be applied (see \autoref{camera_types}).

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.9]{figures/camera_types.png}
	\caption[Camera options]{
		Screenshot showing all of the available camera options in ToView's interface.
	}
	\label{camera_types}
\end{figure}

\subsection[Preprocessing]{Preprocessing}

As mentioned before, scanners sometimes output clouds that may not be optimal for the task at hand. As a consequence, some preprocessing can be needed. ToView offers its users several operations:

\begin{itemize}
	\item \textbf{Voxel grid filter:} Downsampling filter, useful to thin dense point clouds or keep the cloud density uniform. 
	\item \textbf{Statistical outlier removal:} Noise removal filter, it can be used to remove outliers or noise present in the clouds.
	\item \textbf{Radii estimation:} Necessary process if the end user wants to use the two advanced rendering modes. It estimates the value of the point radii.
	\item \textbf{K-d tree building:} Essential process for the visualization of the point clouds. Without a spatial acceleration structure, the clouds would be too big to render or perform any operation.
\end{itemize}

The preprocessing filters are further explained in \autoref{chapter_9}. All of these point cloud operations are exposed to the user through the tools menu in the interface(see \autoref{tools_menu}).

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{figures/tools.png}
	\caption[Tools menu]{
		Screenshot showing all of the available point cloud tools in ToView's interface.
	}
	\label{tools_menu}
\end{figure}

\subsection[Cloud interaction]{Cloud interaction}

One of the main drawbacks of having a simple visualizer without a GUI was the inability to integrate multiple point clouds, and perform modifications on the clouds (see \autoref{mult_clouds}). 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.495]{figures/mult_clouds_int.png}
	\caption[Multiple point cloud integration]{
		Two clouds (a park and a statue) integrated using ToView.
	}
	\label{mult_clouds}
\end{figure}

ToView offers multiple possibilities on this front:

\begin{itemize}
	\item \textbf{Point cloud transformation:} Each cloud can be transformed to the user's liking. 
	\begin{itemize}
		\item \textbf{Translation:} The cloud can be moved through space.
		\item \textbf{Rotation:} The cloud can be rotated.
		\item \textbf{Scaling:} The cloud can be transformed to be bigger or smaller.
	\end{itemize}
	\item \textbf{Multiple point cloud integration:} The user can transform multiple clouds at the same time. This allows the integration of multiple point clouds, correcting positioning errors, wrong coordinate systems, etc.
	\item \textbf{Cloud selector:} Select a cloud to transform, eliminate or perform any operation in an easy way through the interface.
\end{itemize}

The aforementioned features are exposed through the interface in a panel in the interface (see \autoref{cloud_modifiers}). All of these features work in real-time, allowing the user to see the changes made reflected instantly. Clouds can also be added or removed in real-time according to the user's needs.   

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{figures/cloud_modif.png}
	\caption[Cloud interaction]{
		Screenshot showing the cloud interaction menu in ToView's interface.
	}
	\label{cloud_modifiers}
\end{figure}

\subsection[Point picking]{Point picking}

In order to be able to measure distances or segment primitives interactively in the clouds, the visualizer has to be capable of finding the correct point that the user desires in the clouds. This action is called point picking, and is performed in real-time by the visualizer. 

To achieve this, the first step is getting the position the user has clicked in the window. This is done using QT's API and returns two values, the $x$ and $y$ coordinates.

Secondly, the coordinates are transformed so that we have the coordinates of a ray corresponding to that pixel in NDC. The ray origin can be obtained with the following equation:

\begin{equation} \mathbf{r_{start}} = ((x/w - 0.5) * 2, (y/h - 0.5) * 2, 0) \end{equation} 

Being $w$ the width of the window and $h$ the height. The ray end can be obtained with the equation that follows:

\begin{equation} \mathbf{r_{end}} = ((x/w - 0.5) * 2, (y/h - 0.5) * 2, 1) \end{equation} 

Once we have the ray in NDC space, we need to transform it to world space. The operation needed to get the ray in world space is just a matrix multiplication:

\begin{equation} \mathbf{r_{world}} = \textbf{\textit{MVP}}^{-1} \cdot \mathbf{r_{ndc}} \end{equation}

Finally, after the ray in world coordinates is obtained, it is just a matter of obtaining the points that intersect with the ray and return the closest to the viewpoint.

\subsection[Distance measurements]{Distance measurements}

\subsection[Primitive segmentation]{Primitive segmentation}

\subsection[Primitive exportation]{Primitive exportation}

\section[Results]{Results}

